import chromadb
import google.genai as genai
import pandas as pd
from typing import List, Dict, Any, Optional
import logging
import os
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)

class HybridRAGSystem:
    def __init__(self):
        self.client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))
        self.embedding_model = self.client.models.embed_content
        self.llm = self.client.models.generate_content
        self.vector_store = None
        self.qa_chain = None

        
    def initialize_vector_store(self, insurance_data: List[Dict[str, Any]]):
        """
        product_insur_premiums ë°ì´í„°ë¡œ ChromaDB ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”
        """
        try:
            if not insurance_data:
                logger.warning("No insurance data provided for vector store initialization")
                return False
            
            # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            self.vector_store = chromadb.Client()
            
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆìœ¼ë©´ ì‚­ì œ
            try:
                self.vector_store.delete_collection("insurance_coverage")
            except:
                pass
                
            self.collection = self.vector_store.create_collection(
                name="insurance_coverage",
                metadata={"hnsw:space": "cosine"}
            )
            
            # ë¬¸ì„œ ì¤€ë¹„
            documents = []
            metadatas = []
            ids = []
            
            for i, item in enumerate(insurance_data):
                # insur_bojang(ë³´ì¥ì„¤ëª…) í…ìŠ¤íŠ¸ ì¶”ì¶œ
                bojang_text = item.get("insur_bojang", "")
                if bojang_text:
                    documents.append(bojang_text)
                    metadatas.append({
                        "plan_id": item.get("plan_id", ""),
                        "insur_name": item.get("insur_name", ""),
                        "insur_code": item.get("insur_code", ""),
                        "premium_amount": str(item.get("premium_amount", 0))
                    })
                    ids.append(f"doc_{i}")
            
            if not documents:
                logger.warning("No valid documents created from insurance data")
                return False
            
            # ì„ë² ë”© ìƒì„± ë° ì €ì¥
            result = self.embedding_model(
                model="gemini-embedding-001",
                contents=documents
            )
            embeddings = [emb.values for emb in result.embeddings]
            
            # ChromaDBì— ì €ì¥
            self.collection.add(
                embeddings=embeddings,
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            logger.info(f"Vector store initialized successfully with {len(documents)} documents")
            return True
            
        except Exception as e:
            logger.error(f"Error initializing vector store: {e}")
            return False
    
    def search_relevant_docs(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """
        ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰
        """
        try:
            if not hasattr(self, 'collection'):
                logger.warning("Vector store not initialized")
                return []
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embedding_model(
                model="gemini-embedding-001",
                contents=[query]
            )
            
            # ê²€ìƒ‰
            results = self.collection.query(
                query_embeddings=[query_embedding.embeddings[0].values],
                n_results=k
            )
            
            # ê²°ê³¼ í¬ë§·íŒ…
            docs = []
            for i in range(len(results['documents'][0])):
                docs.append({
                    'page_content': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i] if results['metadatas'] else {}
                })
            
            logger.info(f"Found {len(docs)} relevant documents for query: {query}")
            return docs
            
        except Exception as e:
            logger.error(f"Error searching documents: {e}")
            return []
    
    def pandas_analysis(self, df: pd.DataFrame, query: str, comparison_table: Optional[pd.DataFrame] = None) -> str:
        """
        ë³´í—˜ë£Œ ë°ì´í„° ë¶„ì„ - ë¹„êµ í‘œ ìš°ì„  í™œìš©
        """
        try:
            if df is None or df.empty:
                return "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            
            # ë¹„êµ í‘œê°€ ìˆëŠ” ê²½ìš° ë¹„êµ í‘œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ë¶„ì„
            if comparison_table is not None and not comparison_table.empty:
                analysis_df = comparison_table
                data_type = "ë³´í—˜ì‚¬ë³„ ë¹„êµ í‘œ"
            else:
                # ë¹„êµ í‘œê°€ ì—†ëŠ” ê²½ìš° ì›ë³¸ ë°ì´í„°ë¡œ ë¹„êµ í‘œ ìƒì„±
                from data_manager import data_manager
                
                if data_manager.coverage_premiums_df is not None and not data_manager.coverage_premiums_df.empty:
                    # ë™ì ìœ¼ë¡œ ë¹„êµ í‘œ ìƒì„±
                    normalized_df = data_manager.normalize_coverage_amounts(data_manager.coverage_premiums_df)
                    aggregated_df = data_manager.aggregate_coverage_by_code(normalized_df)
                    analysis_df = data_manager.create_comparison_table(aggregated_df)
                    data_type = "ìƒì„±ëœ ë¹„êµ í‘œ"
                else:
                    analysis_df = df
                    data_type = "ì›ë³¸ ë°ì´í„°"
            
            # ë°ì´í„° ë¶„ì„ í”„ë¡¬í”„íŠ¸
            prompt = f"""
            ë‹¤ìŒ {data_type}ë¥¼ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:
            
            ì§ˆë¬¸: {query}
            
            ë°ì´í„° êµ¬ì¡°:
            - Shape: {analysis_df.shape}
            - Columns: {list(analysis_df.columns)}
            - Index: {list(analysis_df.index)}
            
            ë°ì´í„° ìƒ˜í”Œ:
            {analysis_df.head(10).to_string()}
            
            ì£¼ìš” í†µê³„:
            ë³´í—˜ì‚¬ë³„ í‰ê·  ë³´í—˜ë£Œ:
            {str(analysis_df.mean()) if not analysis_df.empty else 'ë°ì´í„° ì—†ìŒ'}
            
            ë¶„ì„ ê°€ì´ë“œ:
            1. ë³´í—˜ë£Œ ë¹„êµ ì‹œ ê°€ì¥ ì €ë ´í•œ ë³´í—˜ì‚¬ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”
            2. íŠ¹ì • ë³´ì¥ í•­ëª©(ì•”ì§„ë‹¨ë¹„, ìƒí•´ë³´ì¥ ë“±)ì— ëŒ€í•´ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”
            3. ë³´í—˜ë£Œ í•©ê³„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìˆœìœ„ë¥¼ ë§¤ê²¨ì£¼ì„¸ìš”
            4. ê° ë³´í—˜ì‚¬ì˜ íŠ¹ì§•ê³¼ ì¥ë‹¨ì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”
            """
            
            response = self.llm(
                model="gemini-3-pro-preview",
                contents=[prompt]
            )
            result = response.text if response and hasattr(response, 'text') else "ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            return result or "ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        except Exception as e:
            logger.error(f"Error in pandas analysis: {e}")
            return f"Error in data analysis: {str(e)}"
    
    def hybrid_chat(self, query: str, df: pd.DataFrame, insurance_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Hybrid RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•œ ì¢…í•©ì ì¸ ì§ˆì˜ì‘ë‹µ - ë¹„êµ í‘œ í™œìš©
        """
        try:
            # 1. ë²¡í„° ê²€ìƒ‰ì„ í†µí•œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            relevant_docs = self.search_relevant_docs(query)
            
            # 2. ë¹„êµ í‘œ ìƒì„± ë° Pandas ë°ì´í„° ë¶„ì„
            pandas_result = ""
            comparison_table = None
            
            if df is not None and not df.empty:
                # ë¹„êµ í‘œ ìƒì„± ì‹œë„
                from data_manager import data_manager
                
                try:
                    if data_manager.coverage_premiums_df is not None and not data_manager.coverage_premiums_df.empty:
                        # ë™ì ìœ¼ë¡œ ë¹„êµ í‘œ ìƒì„±
                        normalized_df = data_manager.normalize_coverage_amounts(data_manager.coverage_premiums_df)
                        aggregated_df = data_manager.aggregate_coverage_by_code(normalized_df)
                        comparison_table = data_manager.create_comparison_table(aggregated_df)
                        
                        # ë¹„êµ í‘œë¥¼ ì‚¬ìš©í•œ ë¶„ì„
                        pandas_result = self.pandas_analysis(df, query, comparison_table)
                    else:
                        pandas_result = self.pandas_analysis(df, query)
                except Exception as e:
                    logger.warning(f"Failed to create comparison table for analysis: {e}")
                    pandas_result = self.pandas_analysis(df, query)
            
            # 3. ì¢…í•© ì‘ë‹µ ìƒì„±
            if relevant_docs and pandas_result:
                # ë‘ ê°€ì§€ ê²°ê³¼ ëª¨ë‘ ìˆëŠ” ê²½ìš°
                # Simple document-based QA using LLM directly
                context = "\n".join([doc['page_content'] for doc in relevant_docs])
                prompt = f"""Based on the following context, please answer the question: {query}

Context:
{context}

Answer:"""
                qa_result = self.llm(
                    model="gemini-3-pro-preview",
                    contents=[prompt]
                ).text
                combined_response = f"""ğŸ“Š **ë°ì´í„° ë¶„ì„ ê²°ê³¼:**\n{pandas_result}\n\nğŸ“‹ **ë³´ì¥ë‚´ìš© ê²€ìƒ‰ ê²°ê³¼:**\n{qa_result}"""
                
            elif relevant_docs:
                # ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ë§Œ ìˆëŠ” ê²½ìš°
                context = "\n".join([doc['page_content'] for doc in relevant_docs])
                prompt = f"""Based on the following context, please answer the question: {query}

Context:
{context}

Answer:"""
                qa_result = self.llm(
                    model="gemini-3-pro-preview",
                    contents=[prompt]
                ).text
                combined_response = f"""ğŸ“‹ **ë³´ì¥ë‚´ìš© ê²€ìƒ‰ ê²°ê³¼:**\n{qa_result}"""
                
            elif pandas_result:
                # Pandas ë¶„ì„ ê²°ê³¼ë§Œ ìˆëŠ” ê²½ìš°
                combined_response = f"""ğŸ“Š **ë°ì´í„° ë¶„ì„ ê²°ê³¼:**\n{pandas_result}"""
                
            else:
                combined_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            return {
                "response": combined_response,
                "sources_found": len(relevant_docs) > 0,
                "data_analysis_available": df is not None and not df.empty,
                "source_count": len(relevant_docs)
            }
            
        except Exception as e:
            logger.error(f"Error in hybrid chat: {e}")
            return {
                "response": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "sources_found": False,
                "data_analysis_available": False,
                "source_count": 0
            }

# ì „ì—­ Hybrid RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
rag_system = HybridRAGSystem()